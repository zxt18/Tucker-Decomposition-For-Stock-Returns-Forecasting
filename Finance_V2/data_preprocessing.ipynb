{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorly.decomposition import CP,tucker, parafac, non_negative_tucker\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FR = pd.read_excel('FINANCIAL_RATIOS_NEW.xlsx', index_col =[0], skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMAT US Equity', 'COKE US Equity', 'WDFC US Equity', 'AAPL US Equity',\n",
       "       'KLAC US Equity', 'SEIC US Equity', 'CSPI US Equity', 'ALOT US Equity',\n",
       "       'AMGN US Equity', 'CAMP US Equity',\n",
       "       ...\n",
       "       'DVN US Equity', 'ORCL US Equity', 'PG US Equity', 'INTC US Equity',\n",
       "       'TTMI US Equity', 'TTEK US Equity', 'WFC US Equity', 'WMT US Equity',\n",
       "       'C US Equity', 'BA US Equity'],\n",
       "      dtype='object', length=220)"
      ]
     },
     "execution_count": 1072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing values from dataframe into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FR = pd.read_excel('FINANCIAL_RATIOS_f.xlsx', index_col =[0])\n",
    "price = None\n",
    "FR_dic = {}\n",
    "FR_list = ['PE', 'PX_LAST', 'PS','PB']\n",
    "n = 0 \n",
    "NUMBER_OF_STOCKS = 220\n",
    "for i,name in enumerate(FR_list) : \n",
    "    FR_dic[name] = (df_FR.iloc[:,n:n+NUMBER_OF_STOCKS]\n",
    "                    .set_index(df_FR.index)\n",
    "                    )\n",
    "\n",
    "    # if name not in ['PX_LAST', 'MCAP'] : \n",
    "        # FR_dic[name] = (FR_dic[name] - FR_dic[name].mean()) / FR_dic[name].std()\n",
    "        \n",
    "    if name in ['PX_LAST'] :\n",
    "\n",
    "        price = FR_dic['PX_LAST']\n",
    "        FR_dic[name] = np.log(FR_dic[name])\n",
    "        FR_dic[name] = FR_dic[name].diff()\n",
    "    \n",
    "\n",
    "    \n",
    "    FR_dic[name] = FR_dic[name][1:]\n",
    "    n += NUMBER_OF_STOCKS + 2\n",
    "\n",
    "COLUMN_NAMES = FR_dic['PE'].columns\n",
    "FR_index = FR_dic['PE'].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMAT US Equity</th>\n",
       "      <th>COKE US Equity</th>\n",
       "      <th>WDFC US Equity</th>\n",
       "      <th>AAPL US Equity</th>\n",
       "      <th>KLAC US Equity</th>\n",
       "      <th>SEIC US Equity</th>\n",
       "      <th>CSPI US Equity</th>\n",
       "      <th>ALOT US Equity</th>\n",
       "      <th>AMGN US Equity</th>\n",
       "      <th>CAMP US Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>DVN US Equity</th>\n",
       "      <th>ORCL US Equity</th>\n",
       "      <th>PG US Equity</th>\n",
       "      <th>INTC US Equity</th>\n",
       "      <th>TTMI US Equity</th>\n",
       "      <th>TTEK US Equity</th>\n",
       "      <th>WFC US Equity</th>\n",
       "      <th>WMT US Equity</th>\n",
       "      <th>C US Equity</th>\n",
       "      <th>BA US Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-11-17</th>\n",
       "      <td>0.920725</td>\n",
       "      <td>0.790533</td>\n",
       "      <td>0.299094</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.953225</td>\n",
       "      <td>0.829484</td>\n",
       "      <td>0.663764</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.753526</td>\n",
       "      <td>0.656345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978271</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.734660</td>\n",
       "      <td>0.968789</td>\n",
       "      <td>0.588856</td>\n",
       "      <td>0.972808</td>\n",
       "      <td>0.671097</td>\n",
       "      <td>0.610858</td>\n",
       "      <td>0.752871</td>\n",
       "      <td>1.042221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-24</th>\n",
       "      <td>0.823815</td>\n",
       "      <td>0.767193</td>\n",
       "      <td>0.260161</td>\n",
       "      <td>0.995344</td>\n",
       "      <td>1.022082</td>\n",
       "      <td>0.831057</td>\n",
       "      <td>0.618387</td>\n",
       "      <td>0.216084</td>\n",
       "      <td>0.663835</td>\n",
       "      <td>0.700463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924439</td>\n",
       "      <td>0.896947</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.828099</td>\n",
       "      <td>0.702060</td>\n",
       "      <td>0.796085</td>\n",
       "      <td>0.430650</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>0.792155</td>\n",
       "      <td>1.107741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-01</th>\n",
       "      <td>0.745419</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>0.309934</td>\n",
       "      <td>0.991250</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.762449</td>\n",
       "      <td>0.622976</td>\n",
       "      <td>0.273581</td>\n",
       "      <td>0.624597</td>\n",
       "      <td>0.792960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984328</td>\n",
       "      <td>0.796322</td>\n",
       "      <td>0.703897</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.593705</td>\n",
       "      <td>0.607564</td>\n",
       "      <td>0.373045</td>\n",
       "      <td>0.508127</td>\n",
       "      <td>0.576063</td>\n",
       "      <td>0.960095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-08</th>\n",
       "      <td>0.806834</td>\n",
       "      <td>0.853188</td>\n",
       "      <td>0.324167</td>\n",
       "      <td>0.914653</td>\n",
       "      <td>0.890031</td>\n",
       "      <td>0.792233</td>\n",
       "      <td>0.708426</td>\n",
       "      <td>0.522080</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.885711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954400</td>\n",
       "      <td>0.589684</td>\n",
       "      <td>0.761502</td>\n",
       "      <td>0.647949</td>\n",
       "      <td>0.641447</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>0.393740</td>\n",
       "      <td>0.454518</td>\n",
       "      <td>0.769086</td>\n",
       "      <td>0.989226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-15</th>\n",
       "      <td>0.648235</td>\n",
       "      <td>0.911753</td>\n",
       "      <td>0.327228</td>\n",
       "      <td>0.854121</td>\n",
       "      <td>0.728860</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>0.470256</td>\n",
       "      <td>0.407438</td>\n",
       "      <td>0.374138</td>\n",
       "      <td>0.839280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787630</td>\n",
       "      <td>0.592830</td>\n",
       "      <td>0.706313</td>\n",
       "      <td>0.593542</td>\n",
       "      <td>0.302576</td>\n",
       "      <td>0.699298</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.360238</td>\n",
       "      <td>1.079196</td>\n",
       "      <td>0.877894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>0.013064</td>\n",
       "      <td>0.165564</td>\n",
       "      <td>0.232073</td>\n",
       "      <td>0.023449</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.154276</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.159267</td>\n",
       "      <td>0.855918</td>\n",
       "      <td>0.103740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661348</td>\n",
       "      <td>0.198829</td>\n",
       "      <td>0.579860</td>\n",
       "      <td>0.117454</td>\n",
       "      <td>0.388168</td>\n",
       "      <td>0.159488</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.069082</td>\n",
       "      <td>-0.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-06</th>\n",
       "      <td>0.216839</td>\n",
       "      <td>0.338704</td>\n",
       "      <td>0.215706</td>\n",
       "      <td>0.379180</td>\n",
       "      <td>0.332483</td>\n",
       "      <td>0.295268</td>\n",
       "      <td>0.372435</td>\n",
       "      <td>0.259133</td>\n",
       "      <td>0.548082</td>\n",
       "      <td>0.227268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.471805</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>0.650765</td>\n",
       "      <td>0.195110</td>\n",
       "      <td>0.145202</td>\n",
       "      <td>0.826072</td>\n",
       "      <td>0.211097</td>\n",
       "      <td>-0.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13</th>\n",
       "      <td>0.029507</td>\n",
       "      <td>0.366630</td>\n",
       "      <td>0.173864</td>\n",
       "      <td>-0.151802</td>\n",
       "      <td>0.108861</td>\n",
       "      <td>-0.126248</td>\n",
       "      <td>0.170237</td>\n",
       "      <td>0.141725</td>\n",
       "      <td>0.638176</td>\n",
       "      <td>-0.035569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835199</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.231608</td>\n",
       "      <td>0.022231</td>\n",
       "      <td>0.490767</td>\n",
       "      <td>-0.117161</td>\n",
       "      <td>-0.001853</td>\n",
       "      <td>0.588303</td>\n",
       "      <td>0.080008</td>\n",
       "      <td>-0.168925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-20</th>\n",
       "      <td>0.174819</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>0.192042</td>\n",
       "      <td>-0.150375</td>\n",
       "      <td>0.282327</td>\n",
       "      <td>0.110766</td>\n",
       "      <td>0.529911</td>\n",
       "      <td>0.148865</td>\n",
       "      <td>0.699472</td>\n",
       "      <td>0.336541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987541</td>\n",
       "      <td>-0.053657</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>0.054102</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>0.033662</td>\n",
       "      <td>-0.087700</td>\n",
       "      <td>0.179703</td>\n",
       "      <td>-0.073271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.846584</td>\n",
       "      <td>0.282257</td>\n",
       "      <td>-0.044283</td>\n",
       "      <td>0.332605</td>\n",
       "      <td>0.226178</td>\n",
       "      <td>0.759327</td>\n",
       "      <td>0.131640</td>\n",
       "      <td>0.875571</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.075574</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.088771</td>\n",
       "      <td>0.499844</td>\n",
       "      <td>0.085115</td>\n",
       "      <td>0.175314</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>-0.010466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows Ã— 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AMAT US Equity  COKE US Equity  WDFC US Equity  AAPL US Equity  \\\n",
       "2006-11-17        0.920725        0.790533        0.299094        0.889780   \n",
       "2006-11-24        0.823815        0.767193        0.260161        0.995344   \n",
       "2006-12-01        0.745419        0.718539        0.309934        0.991250   \n",
       "2006-12-08        0.806834        0.853188        0.324167        0.914653   \n",
       "2006-12-15        0.648235        0.911753        0.327228        0.854121   \n",
       "...                    ...             ...             ...             ...   \n",
       "2022-04-29        0.013064        0.165564        0.232073        0.023449   \n",
       "2022-05-06        0.216839        0.338704        0.215706        0.379180   \n",
       "2022-05-13        0.029507        0.366630        0.173864       -0.151802   \n",
       "2022-05-20        0.174819        0.341748        0.192042       -0.150375   \n",
       "2022-05-27        0.157177        0.846584        0.282257       -0.044283   \n",
       "\n",
       "            KLAC US Equity  SEIC US Equity  CSPI US Equity  ALOT US Equity  \\\n",
       "2006-11-17        0.953225        0.829484        0.663764        0.029398   \n",
       "2006-11-24        1.022082        0.831057        0.618387        0.216084   \n",
       "2006-12-01        0.876556        0.762449        0.622976        0.273581   \n",
       "2006-12-08        0.890031        0.792233        0.708426        0.522080   \n",
       "2006-12-15        0.728860        0.751649        0.470256        0.407438   \n",
       "...                    ...             ...             ...             ...   \n",
       "2022-04-29        0.066688        0.154276        0.069477        0.159267   \n",
       "2022-05-06        0.332483        0.295268        0.372435        0.259133   \n",
       "2022-05-13        0.108861       -0.126248        0.170237        0.141725   \n",
       "2022-05-20        0.282327        0.110766        0.529911        0.148865   \n",
       "2022-05-27        0.332605        0.226178        0.759327        0.131640   \n",
       "\n",
       "            AMGN US Equity  CAMP US Equity  ...  DVN US Equity  \\\n",
       "2006-11-17        0.753526        0.656345  ...       0.978271   \n",
       "2006-11-24        0.663835        0.700463  ...       0.924439   \n",
       "2006-12-01        0.624597        0.792960  ...       0.984328   \n",
       "2006-12-08        0.380172        0.885711  ...       0.954400   \n",
       "2006-12-15        0.374138        0.839280  ...       0.787630   \n",
       "...                    ...             ...  ...            ...   \n",
       "2022-04-29        0.855918        0.103740  ...       0.661348   \n",
       "2022-05-06        0.548082        0.227268  ...       0.972695   \n",
       "2022-05-13        0.638176       -0.035569  ...       0.835199   \n",
       "2022-05-20        0.699472        0.336541  ...       0.987541   \n",
       "2022-05-27        0.875571        0.665848  ...       0.999177   \n",
       "\n",
       "            ORCL US Equity  PG US Equity  INTC US Equity  TTMI US Equity  \\\n",
       "2006-11-17        0.866047      0.734660        0.968789        0.588856   \n",
       "2006-11-24        0.896947      0.767123        0.828099        0.702060   \n",
       "2006-12-01        0.796322      0.703897        0.723577        0.593705   \n",
       "2006-12-08        0.589684      0.761502        0.647949        0.641447   \n",
       "2006-12-15        0.592830      0.706313        0.593542        0.302576   \n",
       "...                    ...           ...             ...             ...   \n",
       "2022-04-29        0.198829      0.579860        0.117454        0.388168   \n",
       "2022-05-06        0.173900      0.471805        0.256990        0.650765   \n",
       "2022-05-13        0.002971      0.231608        0.022231        0.490767   \n",
       "2022-05-20       -0.053657     -0.069306        0.054102        0.657500   \n",
       "2022-05-27        0.075574      0.010497        0.088771        0.499844   \n",
       "\n",
       "            TTEK US Equity  WFC US Equity  WMT US Equity  C US Equity  \\\n",
       "2006-11-17        0.972808       0.671097       0.610858     0.752871   \n",
       "2006-11-24        0.796085       0.430650       0.642886     0.792155   \n",
       "2006-12-01        0.607564       0.373045       0.508127     0.576063   \n",
       "2006-12-08        0.645454       0.393740       0.454518     0.769086   \n",
       "2006-12-15        0.699298       0.330078       0.360238     1.079196   \n",
       "...                    ...            ...            ...          ...   \n",
       "2022-04-29        0.159488       0.028132       0.843362     0.069082   \n",
       "2022-05-06        0.195110       0.145202       0.826072     0.211097   \n",
       "2022-05-13       -0.117161      -0.001853       0.588303     0.080008   \n",
       "2022-05-20       -0.018672       0.033662      -0.087700     0.179703   \n",
       "2022-05-27        0.085115       0.175314       0.020619     0.323404   \n",
       "\n",
       "            BA US Equity  \n",
       "2006-11-17      1.042221  \n",
       "2006-11-24      1.107741  \n",
       "2006-12-01      0.960095  \n",
       "2006-12-08      0.989226  \n",
       "2006-12-15      0.877894  \n",
       "...                  ...  \n",
       "2022-04-29     -0.152900  \n",
       "2022-05-06     -0.014661  \n",
       "2022-05-13     -0.168925  \n",
       "2022-05-20     -0.073271  \n",
       "2022-05-27     -0.010466  \n",
       "\n",
       "[811 rows x 220 columns]"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TI = pd.read_excel('TECH_NEW.xlsx', skiprows=[0])\n",
    "\n",
    "TI_dic = {}\n",
    "TI_list = ['BB_PERCENT', 'HURST', 'MOM', 'ROC','RSI','WLPR']\n",
    "n = 1\n",
    "\n",
    "for _, TI in enumerate(TI_list) : \n",
    "    filter_col = [col for col in df_TI if col.startswith(TI)]\n",
    "    TI_dic[TI] = (df_TI[filter_col]\n",
    "                 .set_axis(COLUMN_NAMES, axis=1)\n",
    "                 .set_index(df_TI['Dates'])\n",
    "                 .iloc[:-1]\n",
    "                 .fillna(method = 'ffill')\n",
    "                 .set_index(FR_index)\n",
    "                 )\n",
    "    # TI_dic[TI] = (TI_dic[TI] - TI_dic[TI].mean()) / TI_dic[TI].std()\n",
    "TI_dic.pop('ROC', None)\n",
    "TI_dic.pop('WLPR', None)\n",
    "TI_dic.pop('BB_PERCENT', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back_duration = 2\n",
    "look_forward = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We attempt to predict 'test_company's' cumulative log returns 2 weeks from now based on historical data which has a lookback period of 13 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import sys\n",
    "# # import numpy as np \n",
    "# # np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# ft1 =  np.stack(FR_dic.values(), axis=2)\n",
    "# ft2 = np.stack(TI_dic.values(), axis=2)\n",
    "# feature_tensor = np.dstack((ft1, ft2))\n",
    "\n",
    "# error_list = []\n",
    "# for n in np.arange(1,150,2) : \n",
    "#     core, factors = tucker(feature_tensor, rank= [711,n,6])\n",
    "#     pc = tl.tenalg.mode_dot(feature_tensor, factors[1].T, mode = 1)\n",
    "#     rec = tl.tucker_to_tensor((core,factors))\n",
    "#     rec_error = tl.norm(rec - feature_tensor)/tl.norm(feature_tensor)\n",
    "#     error_list.append(rec_error)\n",
    "# fig, ax = plt.subplots(1)\n",
    "# ax.plot(np.arange(1,150,2), error_list)\n",
    "# ax.scatter(np.arange(1,150,2), error_list)\n",
    "# ax.grid('On')\n",
    "# ax.set_title(\"Reconstruction error against number of companies\")\n",
    "# ax.set_xlabel(\"Rank\")\n",
    "# ax.set_ylabel(\"Reconstruction error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, the reconstruction error decreases drastically initially once the rank increases above 13, the error no longer drastically anymore. We will hence select a rank of [700,18,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zackx\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3364: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0726374165280644\n",
      "0.08462169363092477\n",
      "607\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# FR_dic.pop('PX_LAST',None)\n",
    "\n",
    "\n",
    "ft1 =  np.stack(FR_dic.values(), axis=2)\n",
    "ft2 = np.stack(TI_dic.values(), axis=2)\n",
    "feature_tensor = np.dstack((ft1, ft2))\n",
    "feature_tensor, feature_tensor2 = feature_tensor[:-200], feature_tensor[-200:]\n",
    "n_stocks = 20\n",
    "\n",
    "\n",
    "def tuck_decomp(feature_tensor, t , s , f) : \n",
    "\n",
    "    core, factors = tucker(feature_tensor, rank= [t,s,f]) # 811 time, 20 stocks, 7 \n",
    "    pc = tl.tenalg.mode_dot(feature_tensor, factors[1].T, mode = 1)\n",
    "\n",
    "    rec = tl.tucker_to_tensor((core,factors))\n",
    "    rec_error = tl.norm(rec - feature_tensor)/tl.norm(feature_tensor)\n",
    "    print(rec_error)\n",
    "    return pc\n",
    "\n",
    "def first_order_diff(pc, length, mode = 2) : \n",
    "    # for n in range(length) : \n",
    "    #     plt.plot(pc[:,n,2])\n",
    "    for i in range(len(pc)-1) :\n",
    "            tmp = pc[i+1,:,mode] - pc[i,:,mode]\n",
    "            pc[i,:,mode] = tmp\n",
    "    pc[1:,:,mode] = pc[:-1,:,mode]\n",
    "    \n",
    "    return pc \n",
    "\n",
    "pc = tuck_decomp(feature_tensor,len(feature_tensor), 20, 7)\n",
    "pc = first_order_diff(pc,n_stocks,mode=0)\n",
    "pc = first_order_diff(pc,n_stocks,mode=1)\n",
    "pc = first_order_diff(pc,n_stocks,mode=2)\n",
    "pc = first_order_diff(pc,n_stocks,mode=3)\n",
    "pc = first_order_diff(pc,n_stocks,mode=4)\n",
    "pc = first_order_diff(pc,n_stocks,mode=5)\n",
    "pc = first_order_diff(pc,n_stocks,mode=6)\n",
    "\n",
    "pc2 = tuck_decomp(feature_tensor2, len(feature_tensor2), 20, 7)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=0)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=1)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=2)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=3)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=4)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=5)\n",
    "pc2 = first_order_diff(pc2,n_stocks,mode=6)\n",
    "\n",
    "pc = pc[1:, : ,:]\n",
    "pc2 = pc2[1:,:,:]\n",
    "\n",
    "diff = True\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(7) : \n",
    "#     plt.figure()\n",
    "#     for n in range(n_stocks) :\n",
    "#         plt.plot(pc[:,n,i])\n",
    "\n",
    "\n",
    "\n",
    "list_of_features = [] #Split the features into different look_back_duration time slots. \n",
    "for i in range(0,len(pc)-look_back_duration-look_forward+1) : \n",
    "    list_of_features.append(pc[i:i+look_back_duration, :,:])\n",
    "\n",
    "\n",
    "list_of_features2 = [] #Split the features into different look_back_duration time slots. \n",
    "for i in range(0,len(pc2)-look_back_duration-look_forward+1) : \n",
    "    list_of_features2.append(pc2[i:i+look_back_duration, :,:])\n",
    "\n",
    "\n",
    "print(len(list_of_features))\n",
    "print(len(list_of_features2))\n",
    "\n",
    "def get_solo_features(solo_df, lb_duration, lf_duration) :\n",
    "    list_of_solo_f = []\n",
    "    #SOLO FEATURES FOR AAPL\n",
    "    for i in range(0,len(solo_df)-lb_duration-lf_duration+1) : \n",
    "        list_of_solo_f.append(solo_df[i:i+lb_duration].to_numpy())\n",
    "    return list_of_solo_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the training data of AAPL \n",
    "solo_df = pd.DataFrame()\n",
    "\n",
    "test_company = 'HAL'\n",
    "k = 0\n",
    "for key,value in FR_dic.items() : \n",
    "    if k == 0 : \n",
    "        solo_df[key] = value[f'{test_company} US Equity']\n",
    "    if k > 0 : \n",
    "        solo_df[key] = value[f'{test_company} US Equity'+ f'.{k}']\n",
    "    k+=1\n",
    "\n",
    "for key,value in TI_dic.items() : \n",
    "    solo_df[key] = value[f'{test_company} US Equity']\n",
    "\n",
    "\n",
    "for col in FR_dic['PX_LAST'] : \n",
    "    if col.startswith(test_company) : \n",
    "        y_predict = FR_dic['PX_LAST'][col]\n",
    "\n",
    "test_comp_returns = pd.DataFrame(y_predict).set_axis(['Log Returns'], axis = 1)\n",
    "test_comp_returns['Cumulative Log Returns'] = test_comp_returns['Log Returns'].cumsum()\n",
    "def get_n_week_retuns(log_returns, look_back_duration, lookforward) : \n",
    "    sdate = test_comp_returns.index.values[0]\n",
    "    edate = test_comp_returns.index.values[-1]\n",
    "    s = (log_returns\n",
    "     .reset_index()\n",
    "     .iloc[look_back_duration:]\n",
    "    )\n",
    "    n_week_retuns = s.rolling(lookforward).sum()\n",
    "    n_week_retuns.index = list(pd.date_range(sdate ,edate + pd.to_timedelta(2, unit='D') ,freq='w') - pd.to_timedelta(2, unit='D'))[:-look_back_duration]\n",
    "    return n_week_retuns.dropna() \n",
    "\n",
    "\n",
    "def to_simple_return(cum_log_ret) : \n",
    "    return np.exp(cum_log_ret) - 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate our target labels\n",
    "\n",
    "1) Predict whether the stock will go +1 or -1 in the next 2 weeks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n",
      "607\n"
     ]
    }
   ],
   "source": [
    "# x_ret_list contains the \n",
    "y_ret =  get_n_week_retuns(test_comp_returns['Log Returns'], look_back_duration = look_back_duration, lookforward = look_forward)\n",
    "\n",
    "y_ret[(y_ret > 0)] = 1\n",
    "\n",
    "y_ret[y_ret <= 0] = -1\n",
    "\n",
    "y_ret1, y_ret2 = y_ret[:-200], y_ret[-200+look_back_duration+1:]\n",
    "\n",
    "\n",
    "list_of_solo_f, list_of_solo_f2 = None, None \n",
    "\n",
    "if diff == True : \n",
    "    y_ret1 = y_ret1[1:]\n",
    "    y_ret2 = y_ret2[1:]\n",
    "    list_of_solo_f = get_solo_features(solo_df, look_back_duration, look_forward)\n",
    "    list_of_solo_f, list_of_solo_f2 = (list_of_solo_f[:-200])[1:], (list_of_solo_f[-200:])[1:]\n",
    "    # print(len(y_ret1))\n",
    "    # print(len(y_ret2))\n",
    "    # print(len(list_of_solo_f))\n",
    "    # print(len(list_of_solo_f2))\n",
    "\n",
    "    # print(len(list_of_features))\n",
    "    # print(len(list_of_features2))\n",
    "print(len(list_of_features))\n",
    "print(len(list_of_solo_f))\n",
    "\n",
    "list_of_combined_features = []\n",
    "list_of_combined_features2 = []\n",
    "for feature_t,solo_feature in zip(list_of_features,list_of_solo_f)  :\n",
    "    solo_feature = solo_feature[:,newaxis,:]\n",
    "    tmp = np.concatenate((feature_t,solo_feature), axis=1)\n",
    "    list_of_combined_features.append(tmp)\n",
    "\n",
    "for feature_t,solo_feature in zip(list_of_features2,list_of_solo_f2)  :\n",
    "    solo_feature = solo_feature[:,newaxis,:]\n",
    "    tmp = np.concatenate((feature_t,solo_feature), axis=1)\n",
    "    list_of_combined_features2.append(tmp)\n",
    "\n",
    "\n",
    "X_Cols = [tensor.flatten() for tensor in list_of_features ]\n",
    "\n",
    "S_Cols = [mat.flatten() for mat in list_of_solo_f]\n",
    "\n",
    "C_Cols = [tensor.flatten() for tensor in list_of_combined_features]\n",
    "\n",
    "\n",
    "X_tot = [tensor.flatten() for tensor in list_of_features2 ]\n",
    "\n",
    "S_tot = [mat.flatten() for mat in list_of_solo_f2]\n",
    "\n",
    "C_tot = [tensor.flatten() for tensor in list_of_combined_features2]\n",
    "\n",
    "X_train ,Y_train = X_Cols, y_ret1\n",
    "X_test ,Y_test =   X_tot[-200:-100], y_ret2[:-100]\n",
    "X_val ,Y_val =   X_tot[-100:], y_ret2[-100:]\n",
    "\n",
    "\n",
    "C_train, Y_train = C_Cols, y_ret1\n",
    "C_test ,Y_test =   C_tot[-200:-100], y_ret2[:-100]\n",
    "C_val ,Y_val =   C_tot[-100:], y_ret2[-100:]\n",
    "\n",
    "\n",
    "# Y_test = y_ret[-200:-100] \n",
    "# Y_val = y_ret[-100:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_val1, S_val1, C_val1, Y_val1 = X_Cols[-120:], S_Cols[-120:], C_Cols[-120:], y_ret[-120:]\n",
    "\n",
    "# X_val2, S_val2, C_val2, Y_val2 = X_val1[-60:], S_val1[-60:], C_val1[-60:], Y_val1[-60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build a RandomForestRegressor model \n",
    "\n",
    "Random Forests is a supervised machine learning algorithim that uses multiple decision trees in aggregate to help make more stable and accurate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from numpy import newaxis\n",
    "\n",
    "#combined_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = np.concatenate([X_Cols[:-350],X_Cols[:-150], X_Cols[len(X_Cols)-350:len(X_Cols)-150]]),  \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_frst_C = RandomForestClassifier(n_estimators= 50, min_samples_split = 2, min_samples_leaf=2,  max_features='auto', max_depth = 12, bootstrap = True, oob_score=True)\n",
    "# rand_frst_X = RandomForestClassifier(n_estimators= 30, min_samples_split = 2, min_samples_leaf=2,  max_features='auto', max_depth = 10, bootstrap = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "def baseline(Y_test, prediction) : \n",
    "    print(len(prediction))\n",
    "    all_ones = np.ones(len(Y_test))\n",
    "    all_neg_ones = np.ones(len(Y_test)) * -1\n",
    "\n",
    "    print(f\"Actual number of ones : {np.count_nonzero(Y_test == 1)}\")\n",
    "    print(f\"Predicted number of ones : {np.count_nonzero(prediction == 1)}\")\n",
    "    # print(f\"Baseline if all were ones : {np.count_nonzero((all_ones==Y_test)) / len(Y_test)}\")\n",
    "\n",
    "    print(f\"Actual number of -1 : {np.count_nonzero(Y_test == -1)}\")\n",
    "    print(f\"Predicted number of -1 : {np.count_nonzero(prediction == -1)}\")\n",
    "    # print(f\"Baseline if all were -1 : {np.count_nonzero((all_neg_ones==Y_test)) / len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 32 is smaller than n_iter=40. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=40,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [False, True],\n",
       "                                        'max_depth': [3, 6, 9, 13],\n",
       "                                        'max_features': ['auto'],\n",
       "                                        'min_samples_leaf': [1, 2],\n",
       "                                        'min_samples_split': [2],\n",
       "                                        'n_estimators': [1000, 2000]},\n",
       "                   random_state=520, verbose=4)"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HYPERPARAMETER TUNING\n",
    "n_estimators = [1000, 2000]\n",
    "\n",
    "max_features = ['auto']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(3,13,4)]\n",
    "\n",
    "min_samples_split = [2]\n",
    "\n",
    "min_samples_leaf = [1,2]\n",
    "\n",
    "bootstrap = [False, True]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'min_samples_split': min_samples_split,\n",
    "\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "'bootstrap' : bootstrap\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Using 5 fold cross validation\n",
    "# Search across 100 different combintations and use all available cores\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf,\n",
    "    param_distributions= random_grid,\n",
    "    n_iter = 40, \n",
    "    verbose= 4,\n",
    "    cv = 3,\n",
    "    random_state=520,\n",
    "    n_jobs = - 1,\n",
    "\n",
    "                        )\n",
    "rf_random.fit(C_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random grid:  {'n_estimators': [1000, 2000], 'max_features': ['auto'], 'max_depth': [3, 6, 9, 13], 'min_samples_split': [2], 'min_samples_leaf': [1, 2], 'bootstrap': [False, True]} \n",
      "\n",
      "Best Parameters:  {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': False}  \n",
      "\n",
      "\n",
      "nan\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': False}\n",
      "0.7973640856672158\n",
      "[[154 123]\n",
      " [  0 330]]\n",
      "0.5104166666666666\n",
      "[[ 8 45]\n",
      " [ 2 41]]\n",
      "0.46\n",
      "[[10 32]\n",
      " [22 36]]\n"
     ]
    }
   ],
   "source": [
    "print('Random grid: ', random_grid, '\\n')\n",
    "\n",
    "print('Best Parameters: ', rf_random.best_params_, ' \\n')\n",
    "print()\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)\n",
    "target_names = ['Red', 'Green']\n",
    "prediction = rf_random.predict(C_train)\n",
    "print(accuracy_score(Y_train, prediction))\n",
    "# print(classification_report(Y_train, prediction, target_names=target_names))\n",
    "print(confusion_matrix(Y_train, prediction))\n",
    "\n",
    "\n",
    "prediction = rf_random.predict(C_test)\n",
    "print(accuracy_score(Y_test, prediction))\n",
    "# print(classification_report(Y_test, prediction, target_names=target_names))\n",
    "print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "\n",
    "prediction_val1= rf_random.predict(C_val)\n",
    "print(accuracy_score(Y_val, prediction_val1))\n",
    "print(confusion_matrix(Y_val, prediction_val1))\n",
    "# print(classification_report(Y_val1, prediction, target_names=target_names))\n",
    "\n",
    "# print(prediction)\n",
    "\n",
    "\n",
    "\n",
    "# prediction_val2 = rf_random.predict(C_val2)\n",
    "# print(accuracy_score(Y_val2, prediction_val2))\n",
    "# print(confusion_matrix(Y_val2, prediction_val2))\n",
    "# print(classification_report(Y_val2, prediction, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(X_train)\n",
    "# print(accuracy_score(Y_train, prediction))\n",
    "# # print(classification_report(Y_train, prediction))\n",
    "# print(confusion_matrix(Y_train, prediction))\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(X_test)\n",
    "# print(accuracy_score(Y_test, prediction))\n",
    "# # print(classification_report(Y_test, prediction, target_names=target_names))\n",
    "# print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(X_val)\n",
    "# print(accuracy_score(Y_val, prediction))\n",
    "# print(confusion_matrix(Y_val, prediction))\n",
    "# # print(classification_report(Y_val1, prediction, target_names=target_names))\n",
    "\n",
    "# print(prediction)\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(S_train)\n",
    "# print(accuracy_score(Y_train, prediction))\n",
    "# # print(classification_report(Y_train, prediction, target_names=target_names))\n",
    "# print(confusion_matrix(Y_train, prediction))\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(S_test)\n",
    "# print(accuracy_score(Y_test, prediction))\n",
    "# # print(classification_report(Y_test, prediction, target_names=target_names))\n",
    "# print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(S_val1)\n",
    "# print(accuracy_score(Y_val1, prediction))\n",
    "# print(confusion_matrix(Y_val1, prediction))\n",
    "# # print(classification_report(Y_val1, prediction, target_names=target_names))\n",
    "\n",
    "# print(prediction)\n",
    "\n",
    "\n",
    "\n",
    "# prediction = rf_random.predict(S_val2)\n",
    "# print(accuracy_score(Y_val2, prediction))\n",
    "# print(confusion_matrix(Y_val2, prediction))\n",
    "# # print(classification_report(Y_val2, prediction, target_names=target_names))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Actual number of ones : 66\n",
      "Predicted number of ones : 65\n",
      "Actual number of -1 : 54\n",
      "Predicted number of -1 : 35\n",
      "60\n",
      "Actual number of ones : 37\n",
      "Predicted number of ones : 60\n",
      "Actual number of -1 : 23\n",
      "Predicted number of -1 : 0\n"
     ]
    }
   ],
   "source": [
    "baseline(Y_val1, prediction_val1)\n",
    "\n",
    "\n",
    "baseline(Y_val2, prediction_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackx\\AppData\\Local\\Temp/ipykernel_9904/1114118841.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rand_frst_C.fit(C_train,Y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[277   0]\n",
      " [  0 330]]\n",
      "0.4375\n",
      "[[18 35]\n",
      " [19 24]]\n",
      "0.5166666666666667\n",
      "[[16 38]\n",
      " [20 46]]\n",
      "0.48333333333333334\n",
      "[[ 5 18]\n",
      " [13 24]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "baseline() missing 1 required positional argument: 'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9904/1114118841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mbaseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: baseline() missing 1 required positional argument: 'prediction'"
     ]
    }
   ],
   "source": [
    "rand_frst_C.fit(C_train,Y_train)\n",
    "\n",
    "\n",
    "prediction = rand_frst_C.predict(C_train)\n",
    "print(accuracy_score(Y_train, prediction))\n",
    "print(confusion_matrix(Y_train, prediction))\n",
    "\n",
    "prediction = rand_frst_C.predict(C_test)\n",
    "print(accuracy_score(Y_test, prediction))\n",
    "print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "prediction = rand_frst_C.predict(C_val1)\n",
    "print(accuracy_score(Y_val1, prediction))\n",
    "print(confusion_matrix(Y_val1, prediction))\n",
    "\n",
    "prediction = rand_frst_C.predict(C_val2)\n",
    "print(accuracy_score(Y_val2, prediction))\n",
    "print(confusion_matrix(Y_val2, prediction))\n",
    "\n",
    "baseline(Y_val1)\n",
    "\n",
    "baseline(Y_val2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998062015503876\n",
      "[[240   0]\n",
      " [  1 275]]\n",
      "0.5813953488372093\n",
      "[[25 49]\n",
      " [23 75]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3080 features, but DecisionTreeClassifier is expecting 280 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9904/410675272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand_frst_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    408\u001b[0m                                     reset=False)\n\u001b[0;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zackx\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 3080 features, but DecisionTreeClassifier is expecting 280 features as input."
     ]
    }
   ],
   "source": [
    "rand_frst_X.fit(X_train,Y_train)\n",
    "prediction = rand_frst_X.predict(X_train)\n",
    "print(accuracy_score(Y_train, prediction))\n",
    "print(confusion_matrix(Y_train, prediction))\n",
    "\n",
    "prediction = rand_frst_X.predict(X_test)\n",
    "print(accuracy_score(Y_test, prediction))\n",
    "print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "prediction = rand_frst_X.predict(X_val)\n",
    "print(accuracy_score(Y_val, prediction))\n",
    "print(confusion_matrix(Y_val, prediction))\n",
    "\n",
    "\n",
    "\n",
    "all_ones = np.ones(len(Y_test))\n",
    "all_neg_ones = np.ones(len(Y_test)) * -1\n",
    "\n",
    "print(f\"Actual number of ones : {np.count_nonzero(Y_test == 1)}\")\n",
    "print(f\"Predicted number of ones : {np.count_nonzero(prediction == 1)}\")\n",
    "print(f\"Baseline if all were ones : {np.count_nonzero((all_ones==Y_test)) / len(Y_test)}\")\n",
    "\n",
    "print(f\"Actual number of -1 : {np.count_nonzero(Y_test == -1)}\")\n",
    "print(f\"Predicted number of -1 : {np.count_nonzero(prediction == -1)}\")\n",
    "print(f\"Baseline if all were -1 : {np.count_nonzero((all_neg_ones==Y_test)) / len(Y_test)}\")   \n",
    "\n",
    "# prediction2 = rand_frst_class.predict(S_test)\n",
    "\n",
    "# print(accuracy_score(Y_test, prediction2))\n",
    "# print(confusion_matrix(Y_test, prediction2))\n",
    "\n",
    "\n",
    "# rand_frst_class.fit(C_train,Y_train)    \n",
    "\n",
    "# prediction3 = rand_frst_class.predict(C_test)\n",
    "\n",
    "# print(accuracy_score(Y_test, prediction3))\n",
    "# print(confusion_matrix(Y_test, prediction3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation : Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5988372093023255\n",
      "[[32 37]\n",
      " [32 71]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "rand_frst_class.fit(X_train,Y_train)    \n",
    "prediction = rand_frst_class.predict(X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, prediction))\n",
    "print(confusion_matrix(Y_test, prediction))\n",
    "\n",
    "\n",
    "\n",
    "# rand_frst_class.fit(S_train,Y_train)    \n",
    "\n",
    "# prediction2 = rand_frst_class.predict(S_test)\n",
    "\n",
    "# print(accuracy_score(Y_test, prediction2))\n",
    "# print(confusion_matrix(Y_test, prediction2))\n",
    "\n",
    "\n",
    "# rand_frst_class.fit(C_train,Y_train)    \n",
    "\n",
    "# prediction3 = rand_frst_class.predict(C_test)\n",
    "\n",
    "# print(accuracy_score(Y_test, prediction3))\n",
    "# print(confusion_matrix(Y_test, prediction3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "# print(np.array(Y_test['Log Returns']))\n",
    "# errors  = abs(predictions - Y_test['Log Returns'])\n",
    "\n",
    "# print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "# mape = 100 * (errors / Y_test)\n",
    "# Calculate and display accuracy\n",
    "# accuracy = 100 - np.mean(mape)\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "\n",
    "\n",
    "# Plot of the predicted log_returns vs actual returns\n",
    "# plt.plot(Y_test['Log Returns'])\n",
    "# plt.plot(predictions, 'o')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# prediction = rand_frst_class.predict(X_test)\n",
    "# mse = mean_squared_error(Y_test, rand_frst_class.predict(X_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e2c2ee5cf96267dcc7744f326d3a9b930733ff27582ed4f98f71c09c9039794"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
